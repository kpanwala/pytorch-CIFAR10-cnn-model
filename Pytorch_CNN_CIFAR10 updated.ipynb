{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch CNN CIFAR10",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgGAiNVykm3T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.utils.data.sampler import SubsetRandomSampler"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxNmGzvGgb4G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "820f1185-bef9-4aae-f8c6-c29ed8cc68f5"
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lqw9b7w6k5Ei",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_transforms = transforms.Compose([transforms.ToTensor(),\n",
        "                                       transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "test_transforms = transforms.Compose([transforms.ToTensor(),\n",
        "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D11dQ3Vou2Ss",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f54c55c2-53cc-4e2e-8e5f-a2df2c52c2fa"
      },
      "source": [
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=train_transforms)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REOiUS18q2xw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_size = 0.2\n",
        "\n",
        "num_train = len(trainset)\n",
        "indices = list(range(num_train))\n",
        "np.random.shuffle(indices)\n",
        "split = int(np.floor(valid_size * num_train))\n",
        "train_idx, valid_idx = indices[split:], indices[:split]\n",
        "\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "valid_sampler = SubsetRandomSampler(valid_idx)"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45qLZoJWrPIn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,sampler=train_sampler,\n",
        "                                         num_workers=2)\n",
        "\n",
        "validloader = torch.utils.data.DataLoader(trainset, batch_size=4, sampler=valid_sampler, num_workers=2)"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8xzl1VhvYE9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "90ea2fd7-d7fd-4c1e-8627-a1e0d7fef4c5"
      },
      "source": [
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                        download=True, transform=test_transforms)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQM_-bv5vjsD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExMJM2z1wAEE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes=10):\n",
        "          super(Net, self).__init__()\n",
        "          self.layer1 = nn.Sequential(\n",
        "              nn.Conv2d(3, 16, kernel_size=5, stride=1, padding=2),\n",
        "              nn.BatchNorm2d(16),\n",
        "              nn.ReLU(),\n",
        "              nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "          self.layer2 = nn.Sequential(\n",
        "              nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
        "              nn.BatchNorm2d(32),\n",
        "              nn.ReLU(),\n",
        "              nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "          self.fc1 = nn.Linear(8*8*32, 64)\n",
        "          self.fc2 = nn.Linear(64, 128) #num_classes\n",
        "          self.fc3 = nn.Linear(128, num_classes)\n",
        "          self.softmax = nn.LogSoftmax(dim=1)\n",
        "          self.dropout = nn.Dropout(0.2)\n",
        "        \n",
        "    def forward(self, x):\n",
        "          out = self.dropout(self.layer1(x))\n",
        "          out = self.dropout(self.layer2(out))\n",
        "          out = out.reshape(out.size(0), -1)\n",
        "          out = self.dropout(self.fc1(out))\n",
        "          out = self.dropout(self.fc2(out))\n",
        "          out = self.fc3(out)\n",
        "          return self.softmax(out)\n",
        "\n",
        "\n",
        "\n",
        "def init_weights(m):\n",
        "    if type(m) == nn.Linear:\n",
        "        torch.nn.init.xavier_uniform_(m.weight)\n",
        "        m.bias.data.fill_(0.01)\n",
        "\n",
        "net = Net().apply(init_weights).to(device)\n"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sj9krYRwYW-N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(net.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01, amsgrad=False)"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_9sAjTZZEh2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "da780e94-6158-4a8a-9fa4-de2ff6e46ded"
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "epochs = 10\n",
        "valid_loss_min = np.Inf\n",
        "total_step = len(trainloader)\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  train_loss = 0.0\n",
        "  valid_loss = 0.0\n",
        "\n",
        "  net.train()\n",
        "  for i,data in enumerate(trainloader):\n",
        "    inputs,labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "    output = net(inputs)\n",
        "    loss = criterion(output,labels)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    train_loss += loss.item()*inputs.size(0)\n",
        "    \n",
        "\n",
        "  net.eval()\n",
        "  for i,data in enumerate(validloader):\n",
        "     data,target = data[0].to(device), data[1].to(device)\n",
        "     # forward pass: compute predicted outputs by passing inputs to the model\n",
        "     output = net(data)\n",
        "     # calculate the batch loss\n",
        "     loss = criterion(output, target)\n",
        "     # update average validation loss \n",
        "     valid_loss += loss.item()*data.size(0)\n",
        "    \n",
        "    # calculate average losses\n",
        "  train_loss = train_loss/len(trainloader.sampler)\n",
        "  valid_loss = valid_loss/len(validloader.sampler)\n",
        "\n",
        "  print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(epoch+1, train_loss, valid_loss))\n",
        "  \n",
        "  # save model if validation loss has decreased\n",
        "  if valid_loss <= valid_loss_min:\n",
        "      print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,valid_loss))\n",
        "      torch.save(net.state_dict(), './cifar_net.pth')\n",
        "      valid_loss_min = valid_loss  "
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss: 1.694843 \tValidation Loss: 1.327869\n",
            "Validation loss decreased (inf --> 1.327869).  Saving model ...\n",
            "Epoch: 2 \tTraining Loss: 1.333359 \tValidation Loss: 1.241535\n",
            "Validation loss decreased (1.327869 --> 1.241535).  Saving model ...\n",
            "Epoch: 3 \tTraining Loss: 1.233050 \tValidation Loss: 1.128666\n",
            "Validation loss decreased (1.241535 --> 1.128666).  Saving model ...\n",
            "Epoch: 4 \tTraining Loss: 1.171696 \tValidation Loss: 1.042166\n",
            "Validation loss decreased (1.128666 --> 1.042166).  Saving model ...\n",
            "Epoch: 5 \tTraining Loss: 1.129386 \tValidation Loss: 1.053908\n",
            "Epoch: 6 \tTraining Loss: 1.102801 \tValidation Loss: 1.045650\n",
            "Epoch: 7 \tTraining Loss: 1.080632 \tValidation Loss: 1.006529\n",
            "Validation loss decreased (1.042166 --> 1.006529).  Saving model ...\n",
            "Epoch: 8 \tTraining Loss: 1.053985 \tValidation Loss: 0.974927\n",
            "Validation loss decreased (1.006529 --> 0.974927).  Saving model ...\n",
            "Epoch: 9 \tTraining Loss: 1.046851 \tValidation Loss: 1.012638\n",
            "Epoch: 10 \tTraining Loss: 1.036176 \tValidation Loss: 0.984138\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cpqg1vd7eBI-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH = './cifar_net.pth'\n",
        "torch.save(net.state_dict(), PATH)"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPBiqVQ5eU_E",
        "colab_type": "text"
      },
      "source": [
        "# **Prediction time**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBibel6JeJhA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c9bf2f61-ab52-4c98-f6e7-171dc2073b62"
      },
      "source": [
        "net = Net().to(device)\n",
        "net.load_state_dict(torch.load(PATH))"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FantGv4QerFO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2df5176c-82c3-4413-e2d9-a62239f3c2f1"
      },
      "source": [
        "correct=0\n",
        "total=0\n",
        "\n",
        "net.eval()\n",
        "with torch.no_grad():\n",
        "  for data in testloader:\n",
        "    images,labels = data[0].to(device), data[1].to(device)\n",
        "    \n",
        "    outputs = net(images)\n",
        "    _ , predicted = torch.max(outputs.data,1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted==labels).sum().item()\n",
        "\n",
        "  print('Accuracy of the network on the 10000 test images: {}'.format(correct*100/total))\n"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 66.88\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}